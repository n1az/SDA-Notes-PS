{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Statistical Data Analysis Problem sheet 4\n",
        "\n",
        "1. Exercise 1\n",
        "\n",
        "* Here random variables are iid and our unknown parameter is *θ*.\n",
        "* Then the maximum spacing estimator of *θ* is defined as a value that maximizes the logarithm of the geometric mean of sample spacings.\n",
        "* As it is a uniform distribution, here the sample spacing of CDF is $$D = \\frac{x_{i}-a}{θ-a}$$\n",
        "\n",
        "* By Claculating Geomateric Mean of the sample spacing and then taking logarithm we get $$S_{n}(a,θ) = \\frac{1}{n+1}\\sum \\limits_{i=1}^{n+1} \\ln {\\frac{x_{i}-a}{θ-a}} $$\n",
        "\n",
        "* As we know the left limit ***a = 0*** , by differentiating the statistics with repect to *θ* we get the estimator for theta using MSE $$θ_{MSE} = \\frac{nx_{n}-x_{1}}{n-1}$$"
      ],
      "metadata": {
        "id": "s6n0FBslZEkn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "mjDcHUozY9hv"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the data\n",
        "dfx = np.loadtxt(\"/content/drive/MyDrive/1-DS/ps4/sampleset_1_problemsheet4_ex1.txt\")\n",
        "dfy = np.loadtxt(\"/content/drive/MyDrive/1-DS/ps4/sampleset_2_problemsheet4_ex1.txt\")\n",
        "dfz = np.loadtxt(\"/content/drive/MyDrive/1-DS/ps4/sampleset_3_problemsheet4_ex1.txt\")"
      ],
      "metadata": {
        "id": "joQJqkNTw7sh"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining theta estimator for unform distribution\n",
        "theta = lambda x,sampsize: (sampsize*x[-1] - x[0])/(sampsize-1)"
      ],
      "metadata": {
        "id": "qhTfoZdsOv_X"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mseThetax = np.array(theta(np.sort(dfx),dfx.size))\n",
        "mseThetay = np.array(theta(np.sort(dfy),dfy.size))\n",
        "mseThetaz = np.array(theta(np.sort(dfz),dfz.size))\n",
        "print(\"Theta using MSE of \\n sampleset 1 : {}  \\n sampleset 2 : {}  \\n sampleset 3 : {}\".format(mseThetax, mseThetay, mseThetaz))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTwQdp9NhYJm",
        "outputId": "d2e87042-bc61-46cd-e857-11f15dde7415"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta using MSE of \n",
            " sampleset 1 : 4.01135  \n",
            " sampleset 2 : 3.9147483673469385  \n",
            " sampleset 3 : 4.029571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Exercise 2\n",
        "\n",
        "* Here the evolution equation is $$z_{n} = 0.99z_{n-1} + \\xi_{n-1}$$\n",
        "\n",
        "* The relative function is $$y_{n} = z_{n}+\\eta_{n}$$\n",
        "\n",
        "* We have to implement kalman filter and ensemble kalman filter and then compare all estimations by mean squared error or ***MSE***."
      ],
      "metadata": {
        "id": "Vd7IBjLlE1E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining standard kalman filter\n",
        "def kalman(data):\n",
        "  me_var = 0.3\n",
        "  de_var = 0.5\n",
        "  mi_var = 0\n",
        "  n = data.shape[0]\n",
        "  emean = np.zeros(n+1)\n",
        "  evar = np.zeros(n+1)\n",
        "  emean[0] = 0\n",
        "  evar[0] = mi_var\n",
        "  for i in range(1, n+1):\n",
        "    fmean = 0.99*emean[i-1]\n",
        "    fvar = 0.99**2 * evar[i-1] + me_var\n",
        "    #calculating kalman gain\n",
        "    kalman_gain = fvar/(fvar+de_var)\n",
        "    # calculating analysis mean and variance\n",
        "    emean[i] = fmean + kalman_gain*(data[i-1] - fmean)\n",
        "    evar[i] = (1 - kalman_gain)*fvar\n",
        "  return emean, evar"
      ],
      "metadata": {
        "id": "FFGrn-bE-qYZ"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data and reference signal values\n",
        "ref = np.loadtxt(\"/content/drive/MyDrive/1-DS/ps4/reference_signal.txt\")\n",
        "mdata = np.loadtxt(\"/content/drive/MyDrive/1-DS/ps4/data.txt\")"
      ],
      "metadata": {
        "id": "hsv9XkLAfzIZ"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying kalman filter on the data\n",
        "kfmean, kfvar = kalman(mdata)"
      ],
      "metadata": {
        "id": "jXZim1UdgZSc"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(kfmean)\n",
        "print(kfvar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PMZ6FWmgxNe",
        "outputId": "cc1f76cb-8846-4aff-e5df-f8bdb4955ae0"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.          0.1496025   0.48710132 ... -0.58526321 -0.77782534\n",
            " -0.47559205]\n",
            "[0.         0.1875     0.24587524 ... 0.26383579 0.26383579 0.26383579]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating mse for standard kalman filter\n",
        "kfmse = np.mean((kfmean - ref)**2)\n",
        "print(kfmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5ZNdOXug8nk",
        "outputId": "a32d01dd-4260-4ec0-a158-96a9e70e88f2"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11351651539008914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining ensemble kalman filter \n",
        "def enskalman(data, ens):\n",
        "  np.random.seed(404)\n",
        "  me_var = 0.3\n",
        "  de_var = 0.5\n",
        "  mi_var = 0\n",
        "  n = data.shape[0]\n",
        "  ens_ini = np.random.normal(0, mi_var**0.5, ens)\n",
        "  ensem = np.zeros((n + 1, ens))\n",
        "  ensem[0] = ens_ini\n",
        "  ens_mean = np.zeros(n+1)\n",
        "  ens_covar = np.zeros(n+1)\n",
        " \n",
        "  for i in range(1, n+1):\n",
        "    m_err = np.random.normal(0, me_var**0.5, ens)\n",
        "    fensem = 0.99*ensem[i-1] + m_err\n",
        "    f_mean = np.mean(fensem)\n",
        "    matx = fensem - f_mean\n",
        "    f_covar = (matx.dot(np.transpose(matx)))/(ens -1)\n",
        "    kalman_gain = f_covar / (f_covar + de_var)\n",
        "    ensem[i] = fensem + kalman_gain*(perturbed_data(data[i-1],de_var,ens)-fensem)\n",
        "    ens_mean[i] = np.mean(ensem[i])\n",
        "  return ens_mean\n",
        "\n"
      ],
      "metadata": {
        "id": "Q7XcbPglhrXb"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating perturbed data for correcting analysis variance\n",
        "\n",
        "def perturbed_data(data, de_var, ens):\n",
        "    m_err_hat = np.random.normal(0,de_var**0.5,ens)\n",
        "    m_err_hat -= np.mean(m_err_hat)\n",
        "    return data - m_err_hat"
      ],
      "metadata": {
        "id": "DnyK2RNSu4x1"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying ensemble kalman filter\n",
        "ens = [5,10,25,50]\n",
        "for m in ens:\n",
        "  ens_mean = enskalman(mdata, m)\n",
        "  ens_kf_mse = np.mean((ens_mean - ref)**2)\n",
        "  print(f\"For ensemble size {m} , MSE is : {ens_kf_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBO3eXsCp4N7",
        "outputId": "7eb194fd-1af3-43b2-96fa-9e2bec40b35a"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For ensemble size 5 , MSE is : 0.15886513895276547\n",
            "For ensemble size 10 , MSE is : 0.1266817408205558\n",
            "For ensemble size 25 , MSE is : 0.11970358943085674\n",
            "For ensemble size 50 , MSE is : 0.11632277074743622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that the standard kalman filter is better with respect to MSE values. But with ensemble kalman filter, upon increasing the ensemble, the error is decreasing. The ensemble kalman filter is computationally less expensive for higher dimensions."
      ],
      "metadata": {
        "id": "1Js3vKO1zWUz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n2CTRZ5zx-OK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}